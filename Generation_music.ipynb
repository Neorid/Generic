{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generation_music.ipynb",
      "provenance": [],
      "mount_file_id": "1nv_W-P9BXLNCr4a6GUo0zyc9UXkEsrG4",
      "authorship_tag": "ABX9TyMZ50C1CGVqlNAjFEIrH5S7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neorid/Generic/blob/main/Generation_music.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aNW_4Sfd0SY",
        "outputId": "9bf89ad2-ef50-4538-c4bf-fd25711dcb16"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEvvEzgO9Peh"
      },
      "source": [
        "Иморптируем файлы песочницу\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "ZO1CoeeTtete",
        "outputId": "2b35efc5-abf7-4015-91f0-eceecc155462"
      },
      "source": [
        "from google.colab import files\r\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d294e52d-a661-439c-8b53-52c12aba04b2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d294e52d-a661-439c-8b53-52c12aba04b2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp0UcnWZZUE7"
      },
      "source": [
        "# Example one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT41Tb7g9aCu"
      },
      "source": [
        "Добавление библиотек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsaUGa-oPl9Y"
      },
      "source": [
        "import glob\r\n",
        "import pickle\r\n",
        "import numpy\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "from music21 import converter, instrument, note, chord, stream\r\n",
        "from tensorflow.keras import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Dropout\r\n",
        "from keras.layers import LSTM\r\n",
        "from keras.layers import Activation\r\n",
        "from keras.layers import BatchNormalization as BatchNorm\r\n",
        "from keras.utils import np_utils\r\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONAKypsF9kGR"
      },
      "source": [
        "Делаем взаимосвязь с google disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EajNuKdzhjIt"
      },
      "source": [
        "!ls /content/gdrive/\"MyDrive\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnxWyK75opSl"
      },
      "source": [
        "!cp /content/gdrive/'MyDrive'/Classical-Piano-Compose/data/notes ."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_3SIkzliTiz"
      },
      "source": [
        "!cp /content/gdrive/'MyDrive'/Classical-Piano-Compose/midi_songs/*mid ."
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJm5O_dApKDu",
        "outputId": "ac07f582-89cb-4bc6-9432-e41facbe55a0"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 0fithos.mid\n",
            " 8.mid\n",
            " ahead_on_our_way_piano.mid\n",
            " AT.mid\n",
            " balamb.mid\n",
            " bcm.mid\n",
            " BlueStone_LastDungeon.mid\n",
            " braska.mid\n",
            " caitsith.mid\n",
            " Cids.mid\n",
            " cosmo.mid\n",
            " costadsol.mid\n",
            " dayafter.mid\n",
            " decisive.mid\n",
            " dontbeafraid.mid\n",
            " DOS.mid\n",
            " drive\n",
            " electric_de_chocobo.mid\n",
            " Eternal_Harvest.mid\n",
            " EyesOnMePiano.mid\n",
            " ff11_awakening_piano.mid\n",
            " ff1battp.mid\n",
            "'FF3_Battle_(Piano).mid'\n",
            "'FF3_Third_Phase_Final_(Piano).mid'\n",
            " ff4-airship.mid\n",
            " Ff4-BattleLust.mid\n",
            " ff4-fight1.mid\n",
            " FF4.mid\n",
            " ff4pclov.mid\n",
            " ff4_piano_collections-main_theme.mid\n",
            " ff4-town.mid\n",
            " FF6epitaph_piano.mid\n",
            " ff6shap.mid\n",
            " Ff7-Cinco.mid\n",
            " Ff7-Jenova_Absolute.mid\n",
            " ff7-mainmidi.mid\n",
            " Ff7-One_Winged.mid\n",
            " ff7themep.mid\n",
            " ff8-lfp.mid\n",
            " FF8_Shuffle_or_boogie_pc.mid\n",
            " FFIII_Edgar_And_Sabin_Piano.mid\n",
            " FFIX_Piano.mid\n",
            " FFIXQuMarshP.mid\n",
            " FFVII_BATTLE.mid\n",
            "'FFX_-_Ending_Theme_(Piano_Version)_-_by_Angel_FF.mid'\n",
            "'Fiend_Battle_(Piano).mid'\n",
            "'Fierce_Battle_(Piano).mid'\n",
            " figaro.mid\n",
            " Finalfantasy5gilgameshp.mid\n",
            " Finalfantasy6fanfarecomplete.mid\n",
            " Final_Fantasy_7_-_Judgement_Day_Piano.mid\n",
            " Final_Fantasy_Matouyas_Cave_Piano.mid\n",
            " fortresscondor.mid\n",
            " Fyw_piano.mid\n",
            " gdrive\n",
            " gerudo.mid\n",
            " goldsaucer.mid\n",
            " Gold_Silver_Rival_Battle.mid\n",
            " great_war.mid\n",
            " HighwindTakestotheSkies.mid\n",
            " In_Zanarkand.mid\n",
            " JENOVA.mid\n",
            " Kingdom_Hearts_Dearly_Beloved.mid\n",
            " Kingdom_Hearts_Traverse_Town.mid\n",
            " Life_Stream.mid\n",
            " lurk_in_dark.mid\n",
            " mining.mid\n",
            " notes\n",
            " Oppressed.mid\n",
            " OTD5YA.mid\n",
            " path_of_repentance.mid\n",
            " pkelite4.mid\n",
            " Rachel_Piano_tempofix.mid\n",
            " redwings.mid\n",
            " relmstheme-piano.mid\n",
            " roseofmay-piano.mid\n",
            " rufus.mid\n",
            " Rydia_pc.mid\n",
            " sample_data\n",
            " sandy.mid\n",
            " sera_.mid\n",
            " sobf.mid\n",
            " Still_Alive-1.mid\n",
            "'Suteki_Da_Ne_(Piano_Version).mid'\n",
            " test_output.mid\n",
            " thenightmarebegins.mid\n",
            " thoughts.mid\n",
            " tifap.mid\n",
            " tpirtsd-piano.mid\n",
            " traitor.mid\n",
            " ultimafro.mid\n",
            " ultros.mid\n",
            " VincentPiano.mid\n",
            " ViviinAlexandria.mid\n",
            " waltz_de_choco.mid\n",
            " weights-improvement-01-4.7639-bigger.hdf5\n",
            " weights-improvement-02-4.7132-bigger.hdf5\n",
            " weights-improvement-03-4.7102-bigger.hdf5\n",
            " weights-improvement-04-4.7087-bigger.hdf5\n",
            " weights-improvement-05-4.7081-bigger.hdf5\n",
            " weights-improvement-07-4.7075-bigger.hdf5\n",
            " weights-improvement-09-4.7074-bigger.hdf5\n",
            " weights-improvement-100-4.6013-bigger.hdf5\n",
            " weights-improvement-101-4.5588-bigger.hdf5\n",
            " weights-improvement-102-4.5020-bigger.hdf5\n",
            " weights-improvement-103-4.4139-bigger.hdf5\n",
            " weights-improvement-104-4.3109-bigger.hdf5\n",
            " weights-improvement-10-4.7071-bigger.hdf5\n",
            " weights-improvement-105-4.1781-bigger.hdf5\n",
            " weights-improvement-106-4.0134-bigger.hdf5\n",
            " weights-improvement-107-3.8224-bigger.hdf5\n",
            " weights-improvement-108-3.6267-bigger.hdf5\n",
            " weights-improvement-109-3.4297-bigger.hdf5\n",
            " weights-improvement-110-3.2325-bigger.hdf5\n",
            " weights-improvement-111-3.0503-bigger.hdf5\n",
            " weights-improvement-112-2.8718-bigger.hdf5\n",
            " weights-improvement-113-2.6953-bigger.hdf5\n",
            " weights-improvement-114-2.5416-bigger.hdf5\n",
            " weights-improvement-115-2.3851-bigger.hdf5\n",
            " weights-improvement-116-2.2327-bigger.hdf5\n",
            " weights-improvement-117-2.0876-bigger.hdf5\n",
            " weights-improvement-118-1.9471-bigger.hdf5\n",
            " weights-improvement-119-1.8169-bigger.hdf5\n",
            " weights-improvement-120-1.6893-bigger.hdf5\n",
            " weights-improvement-121-1.5774-bigger.hdf5\n",
            " weights-improvement-122-1.4595-bigger.hdf5\n",
            " weights-improvement-123-1.3678-bigger.hdf5\n",
            " weights-improvement-124-1.2682-bigger.hdf5\n",
            " weights-improvement-125-1.1724-bigger.hdf5\n",
            " weights-improvement-126-1.1029-bigger.hdf5\n",
            " weights-improvement-127-1.0239-bigger.hdf5\n",
            " weights-improvement-128-0.9530-bigger.hdf5\n",
            " weights-improvement-129-0.8871-bigger.hdf5\n",
            " weights-improvement-130-0.8263-bigger.hdf5\n",
            " weights-improvement-131-0.7744-bigger.hdf5\n",
            " weights-improvement-132-0.7295-bigger.hdf5\n",
            " weights-improvement-133-0.6795-bigger.hdf5\n",
            " weights-improvement-134-0.6403-bigger.hdf5\n",
            " weights-improvement-135-0.6025-bigger.hdf5\n",
            " weights-improvement-136-0.5637-bigger.hdf5\n",
            " weights-improvement-137-0.5349-bigger.hdf5\n",
            " weights-improvement-138-0.5102-bigger.hdf5\n",
            " weights-improvement-139-0.4793-bigger.hdf5\n",
            " weights-improvement-140-0.4613-bigger.hdf5\n",
            " weights-improvement-141-0.4324-bigger.hdf5\n",
            " weights-improvement-142-0.4111-bigger.hdf5\n",
            " weights-improvement-143-0.3983-bigger.hdf5\n",
            " weights-improvement-144-0.3774-bigger.hdf5\n",
            " weights-improvement-145-0.3615-bigger.hdf5\n",
            " weights-improvement-146-0.3495-bigger.hdf5\n",
            " weights-improvement-147-0.3387-bigger.hdf5\n",
            " weights-improvement-148-0.3269-bigger.hdf5\n",
            " weights-improvement-149-0.3202-bigger.hdf5\n",
            " weights-improvement-150-0.3122-bigger.hdf5\n",
            " weights-improvement-151-0.2943-bigger.hdf5\n",
            " weights-improvement-152-0.2880-bigger.hdf5\n",
            " weights-improvement-153-0.2814-bigger.hdf5\n",
            " weights-improvement-154-0.2690-bigger.hdf5\n",
            " weights-improvement-155-0.2618-bigger.hdf5\n",
            " weights-improvement-156-0.2582-bigger.hdf5\n",
            " weights-improvement-157-0.2510-bigger.hdf5\n",
            " weights-improvement-158-0.2453-bigger.hdf5\n",
            " weights-improvement-159-0.2419-bigger.hdf5\n",
            " weights-improvement-160-0.2327-bigger.hdf5\n",
            " weights-improvement-161-0.2255-bigger.hdf5\n",
            " weights-improvement-162-0.2235-bigger.hdf5\n",
            " weights-improvement-163-0.2193-bigger.hdf5\n",
            " weights-improvement-164-0.2179-bigger.hdf5\n",
            " weights-improvement-165-0.2122-bigger.hdf5\n",
            " weights-improvement-166-0.2046-bigger.hdf5\n",
            " weights-improvement-168-0.2000-bigger.hdf5\n",
            " weights-improvement-169-0.1969-bigger.hdf5\n",
            " weights-improvement-170-0.1956-bigger.hdf5\n",
            " weights-improvement-171-0.1912-bigger.hdf5\n",
            " weights-improvement-172-0.1871-bigger.hdf5\n",
            " weights-improvement-173-0.1810-bigger.hdf5\n",
            " weights-improvement-174-0.1803-bigger.hdf5\n",
            " weights-improvement-176-0.1731-bigger.hdf5\n",
            " weights-improvement-179-0.1691-bigger.hdf5\n",
            " weights-improvement-180-0.1688-bigger.hdf5\n",
            " weights-improvement-181-0.1650-bigger.hdf5\n",
            " weights-improvement-183-0.1590-bigger.hdf5\n",
            " weights-improvement-186-0.1569-bigger.hdf5\n",
            " weights-improvement-188-0.1562-bigger.hdf5\n",
            " weights-improvement-189-0.1553-bigger.hdf5\n",
            " weights-improvement-190-0.1521-bigger.hdf5\n",
            " weights-improvement-192-0.1512-bigger.hdf5\n",
            " weights-improvement-193-0.1499-bigger.hdf5\n",
            " weights-improvement-195-0.1495-bigger.hdf5\n",
            " weights-improvement-196-0.1432-bigger.hdf5\n",
            " weights-improvement-197-0.1414-bigger.hdf5\n",
            " weights-improvement-26-4.7062-bigger.hdf5\n",
            " weights-improvement-27-4.7052-bigger.hdf5\n",
            " weights-improvement-28-4.7045-bigger.hdf5\n",
            " weights-improvement-29-4.7044-bigger.hdf5\n",
            " weights-improvement-35-4.7044-bigger.hdf5\n",
            " weights-improvement-99-4.6475-bigger.hdf5\n",
            " z_aeristhemepiano.mid\n",
            " Zelda_Overworld.mid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgG6SrX5RpdX"
      },
      "source": [
        "!cp *.hdf5 /content/gdrive/\"MyDrive\"/network_train"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsloiRGB9vOQ"
      },
      "source": [
        "Часть на обучение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgYtSesZPuzA"
      },
      "source": [
        "def train_network():\r\n",
        "    \"\"\" Train a Neural Network to generate music \"\"\"\r\n",
        "    notes = get_notes()\r\n",
        "    # get amount of pitch names\r\n",
        "    n_vocab = len(set(notes))\r\n",
        "\r\n",
        "    network_input, network_output = prepare_sequences(notes, n_vocab)\r\n",
        "\r\n",
        "    model = create_network(network_input, n_vocab)\r\n",
        "\r\n",
        "    train(model, network_input, network_output)\r\n",
        "\r\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nCyHynrRpZA"
      },
      "source": [
        "def get_notes():\r\n",
        "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\r\n",
        "    notes = []\r\n",
        "\r\n",
        "    for file in glob.glob(\"*.mid\"):\r\n",
        "        midi = converter.parse(file)\r\n",
        "\r\n",
        "        print(\"Parsing %s\" % file)\r\n",
        "\r\n",
        "        notes_to_parse = None\r\n",
        "\r\n",
        "        try: # file has instrument parts\r\n",
        "            s2 = instrument.partitionByInstrument(midi)\r\n",
        "            notes_to_parse = s2.parts[0].recurse() \r\n",
        "        except: # file has notes in a flat structure\r\n",
        "            notes_to_parse = midi.flat.notes\r\n",
        "\r\n",
        "        for element in notes_to_parse:\r\n",
        "            if isinstance(element, note.Note):\r\n",
        "                notes.append(str(element.pitch))\r\n",
        "            elif isinstance(element, chord.Chord):\r\n",
        "                notes.append('.'.join(str(n) for n in element.normalOrder))\r\n",
        "\r\n",
        "    with open('notes', 'wb') as filepath:\r\n",
        "        pickle.dump(notes, filepath)\r\n",
        "\r\n",
        "    return notes"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-umoHL5Pxvh"
      },
      "source": [
        "def prepare_sequences(notes, n_vocab):\r\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\r\n",
        "    sequence_length = 100\r\n",
        "\r\n",
        "    # get all pitch names\r\n",
        "    pitchnames = sorted(set(item for item in notes))\r\n",
        "\r\n",
        "     # create a dictionary to map pitches to integers\r\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\r\n",
        "\r\n",
        "    network_input = []\r\n",
        "    network_output = []\r\n",
        "\r\n",
        "    # create input sequences and the corresponding outputs\r\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\r\n",
        "        sequence_in = notes[i:i + sequence_length]\r\n",
        "        sequence_out = notes[i + sequence_length]\r\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\r\n",
        "        network_output.append(note_to_int[sequence_out])\r\n",
        "\r\n",
        "    n_patterns = len(network_input)\r\n",
        "\r\n",
        "    # reshape the input into a format compatible with LSTM layers\r\n",
        "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\r\n",
        "    # normalize input\r\n",
        "    network_input = network_input / float(n_vocab)\r\n",
        "\r\n",
        "    network_output = np_utils.to_categorical(network_output)\r\n",
        "\r\n",
        "    return (network_input, network_output)\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yugn2hbGP-OH",
        "outputId": "7a881d1c-4cb1-477f-c660-02bfdf4a227c"
      },
      "source": [
        "def create_network(network_input, n_vocab):\r\n",
        "    \"\"\" create the structure of the neural network \"\"\"\r\n",
        "    model = Sequential()\r\n",
        "    model.add(LSTM(\r\n",
        "        512,\r\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\r\n",
        "        return_sequences=True\r\n",
        "    ))\r\n",
        "    model.add(Dropout(0.3))\r\n",
        "    model.add(LSTM(512, return_sequences=True))\r\n",
        "    model.add(Dropout(0.3))\r\n",
        "    model.add(LSTM(512))\r\n",
        "    model.add(Dense(256))\r\n",
        "    model.add(Dropout(0.3))\r\n",
        "    model.add(Dense(n_vocab))\r\n",
        "    model.add(Activation('softmax'))\r\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\r\n",
        "\r\n",
        "    return model\r\n",
        "\r\n",
        "def train(model, network_input, network_output):\r\n",
        "    \"\"\" train the neural network \"\"\"\r\n",
        "    filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\r\n",
        "    checkpoint = ModelCheckpoint(\r\n",
        "        filepath,\r\n",
        "        monitor='loss',\r\n",
        "        verbose=0,\r\n",
        "        save_best_only=True,\r\n",
        "        mode='min'\r\n",
        "    )\r\n",
        "    callbacks_list = [checkpoint]\r\n",
        "\r\n",
        "    model.fit(network_input, network_output, epochs=200, batch_size=128, callbacks=callbacks_list)\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    train_network()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing Zelda_Overworld.mid\n",
            "Parsing Suteki_Da_Ne_(Piano_Version).mid\n",
            "Parsing FFVII_BATTLE.mid\n",
            "Parsing VincentPiano.mid\n",
            "Parsing costadsol.mid\n",
            "Parsing dayafter.mid\n",
            "Parsing relmstheme-piano.mid\n",
            "Parsing ff1battp.mid\n",
            "Parsing ultros.mid\n",
            "Parsing braska.mid\n",
            "Parsing ff4-airship.mid\n",
            "Parsing redwings.mid\n",
            "Parsing ultimafro.mid\n",
            "Parsing Finalfantasy6fanfarecomplete.mid\n",
            "Parsing dontbeafraid.mid\n",
            "Parsing caitsith.mid\n",
            "Parsing rufus.mid\n",
            "Parsing FF6epitaph_piano.mid\n",
            "Parsing Still_Alive-1.mid\n",
            "Parsing Kingdom_Hearts_Dearly_Beloved.mid\n",
            "Parsing ff8-lfp.mid\n",
            "Parsing ff7-mainmidi.mid\n",
            "Parsing electric_de_chocobo.mid\n",
            "Parsing roseofmay-piano.mid\n",
            "Parsing balamb.mid\n",
            "Parsing great_war.mid\n",
            "Parsing Rachel_Piano_tempofix.mid\n",
            "Parsing Final_Fantasy_Matouyas_Cave_Piano.mid\n",
            "Parsing Ff7-Cinco.mid\n",
            "Parsing Life_Stream.mid\n",
            "Parsing Cids.mid\n",
            "Parsing ahead_on_our_way_piano.mid\n",
            "Parsing sandy.mid\n",
            "Parsing Rydia_pc.mid\n",
            "Parsing sobf.mid\n",
            "Parsing BlueStone_LastDungeon.mid\n",
            "Parsing Final_Fantasy_7_-_Judgement_Day_Piano.mid\n",
            "Parsing EyesOnMePiano.mid\n",
            "Parsing ViviinAlexandria.mid\n",
            "Parsing Ff4-BattleLust.mid\n",
            "Parsing FF3_Battle_(Piano).mid\n",
            "Parsing fortresscondor.mid\n",
            "Parsing FFIII_Edgar_And_Sabin_Piano.mid\n",
            "Parsing gerudo.mid\n",
            "Parsing path_of_repentance.mid\n",
            "Parsing Eternal_Harvest.mid\n",
            "Parsing mining.mid\n",
            "Parsing z_aeristhemepiano.mid\n",
            "Parsing JENOVA.mid\n",
            "Parsing pkelite4.mid\n",
            "Parsing DOS.mid\n",
            "Parsing thoughts.mid\n",
            "Parsing goldsaucer.mid\n",
            "Parsing FFX_-_Ending_Theme_(Piano_Version)_-_by_Angel_FF.mid\n",
            "Parsing ff11_awakening_piano.mid\n",
            "Parsing sera_.mid\n",
            "Parsing Ff7-One_Winged.mid\n",
            "Parsing ff4_piano_collections-main_theme.mid\n",
            "Parsing FF3_Third_Phase_Final_(Piano).mid\n",
            "Parsing FF8_Shuffle_or_boogie_pc.mid\n",
            "Parsing tpirtsd-piano.mid\n",
            "Parsing decisive.mid\n",
            "Parsing ff6shap.mid\n",
            "Parsing 0fithos.mid\n",
            "Parsing In_Zanarkand.mid\n",
            "Parsing OTD5YA.mid\n",
            "Parsing ff4-town.mid\n",
            "Parsing Ff7-Jenova_Absolute.mid\n",
            "Parsing Finalfantasy5gilgameshp.mid\n",
            "Parsing waltz_de_choco.mid\n",
            "Parsing FFIXQuMarshP.mid\n",
            "Parsing FF4.mid\n",
            "Parsing 8.mid\n",
            "Parsing Kingdom_Hearts_Traverse_Town.mid\n",
            "Parsing ff4pclov.mid\n",
            "Parsing FFIX_Piano.mid\n",
            "Parsing lurk_in_dark.mid\n",
            "Parsing thenightmarebegins.mid\n",
            "Parsing ff4-fight1.mid\n",
            "Parsing Oppressed.mid\n",
            "Parsing HighwindTakestotheSkies.mid\n",
            "Parsing Fyw_piano.mid\n",
            "Parsing Gold_Silver_Rival_Battle.mid\n",
            "Parsing traitor.mid\n",
            "Parsing Fierce_Battle_(Piano).mid\n",
            "Parsing ff7themep.mid\n",
            "Parsing AT.mid\n",
            "Parsing tifap.mid\n",
            "Parsing cosmo.mid\n",
            "Parsing Fiend_Battle_(Piano).mid\n",
            "Parsing bcm.mid\n",
            "Parsing figaro.mid\n",
            "Epoch 1/200\n",
            "446/446 [==============================] - 70s 135ms/step - loss: 4.8571\n",
            "Epoch 2/200\n",
            "446/446 [==============================] - 63s 140ms/step - loss: 4.7126\n",
            "Epoch 3/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7114\n",
            "Epoch 4/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7089\n",
            "Epoch 5/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7125\n",
            "Epoch 6/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7100\n",
            "Epoch 7/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7075\n",
            "Epoch 8/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7070\n",
            "Epoch 9/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7115\n",
            "Epoch 10/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7018\n",
            "Epoch 11/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7050\n",
            "Epoch 12/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7028\n",
            "Epoch 13/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7060\n",
            "Epoch 14/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7016\n",
            "Epoch 15/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7026\n",
            "Epoch 16/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7073\n",
            "Epoch 17/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7148\n",
            "Epoch 18/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7071\n",
            "Epoch 19/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7084\n",
            "Epoch 20/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7058\n",
            "Epoch 21/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7083\n",
            "Epoch 22/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7114\n",
            "Epoch 23/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7092\n",
            "Epoch 24/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7122\n",
            "Epoch 25/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7194\n",
            "Epoch 26/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.6977\n",
            "Epoch 27/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7083\n",
            "Epoch 28/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7027\n",
            "Epoch 29/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7046\n",
            "Epoch 30/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7047\n",
            "Epoch 31/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7043\n",
            "Epoch 32/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7020\n",
            "Epoch 33/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7062\n",
            "Epoch 34/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7090\n",
            "Epoch 35/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7046\n",
            "Epoch 36/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7011\n",
            "Epoch 37/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7068\n",
            "Epoch 38/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7036\n",
            "Epoch 39/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7030\n",
            "Epoch 40/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7072\n",
            "Epoch 41/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7020\n",
            "Epoch 42/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7068\n",
            "Epoch 43/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7082\n",
            "Epoch 44/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7038\n",
            "Epoch 45/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7106\n",
            "Epoch 46/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.6992\n",
            "Epoch 47/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7139\n",
            "Epoch 48/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7089\n",
            "Epoch 49/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.6950\n",
            "Epoch 50/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7107\n",
            "Epoch 51/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7013\n",
            "Epoch 52/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7051\n",
            "Epoch 53/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7111\n",
            "Epoch 54/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7157\n",
            "Epoch 55/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7087\n",
            "Epoch 56/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7039\n",
            "Epoch 57/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7120\n",
            "Epoch 58/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7159\n",
            "Epoch 59/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7045\n",
            "Epoch 60/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7070\n",
            "Epoch 61/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7109\n",
            "Epoch 62/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7203\n",
            "Epoch 63/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7180\n",
            "Epoch 64/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7113\n",
            "Epoch 65/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7079\n",
            "Epoch 66/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7146\n",
            "Epoch 67/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7195\n",
            "Epoch 68/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7157\n",
            "Epoch 69/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7146\n",
            "Epoch 70/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7216\n",
            "Epoch 71/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7151\n",
            "Epoch 72/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7300\n",
            "Epoch 73/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7365\n",
            "Epoch 74/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7316\n",
            "Epoch 75/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7321\n",
            "Epoch 76/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7366\n",
            "Epoch 77/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7532\n",
            "Epoch 78/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7605\n",
            "Epoch 79/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7634\n",
            "Epoch 80/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7701\n",
            "Epoch 81/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7744\n",
            "Epoch 82/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7804\n",
            "Epoch 83/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7925\n",
            "Epoch 84/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7935\n",
            "Epoch 85/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.7941\n",
            "Epoch 86/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.8147\n",
            "Epoch 87/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.8264\n",
            "Epoch 88/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.8264\n",
            "Epoch 89/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.8244\n",
            "Epoch 90/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.8214\n",
            "Epoch 91/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.8132\n",
            "Epoch 92/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.8134\n",
            "Epoch 93/200\n",
            "446/446 [==============================] - 62s 138ms/step - loss: 4.8241\n",
            "Epoch 94/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.8041\n",
            "Epoch 95/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.8132\n",
            "Epoch 96/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.8053\n",
            "Epoch 97/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.8063\n",
            "Epoch 98/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.7745\n",
            "Epoch 99/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.6591\n",
            "Epoch 100/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.6099\n",
            "Epoch 101/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.5592\n",
            "Epoch 102/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.5151\n",
            "Epoch 103/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.4329\n",
            "Epoch 104/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.3279\n",
            "Epoch 105/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.1883\n",
            "Epoch 106/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 4.0309\n",
            "Epoch 107/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 3.8488\n",
            "Epoch 108/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 3.6307\n",
            "Epoch 109/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 3.4468\n",
            "Epoch 110/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 3.2464\n",
            "Epoch 111/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 3.0454\n",
            "Epoch 112/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 2.8640\n",
            "Epoch 113/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 2.6705\n",
            "Epoch 114/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 2.5165\n",
            "Epoch 115/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 2.3608\n",
            "Epoch 116/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 2.1854\n",
            "Epoch 117/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 2.0463\n",
            "Epoch 118/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 1.8946\n",
            "Epoch 119/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 1.7738\n",
            "Epoch 120/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 1.6401\n",
            "Epoch 121/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 1.5342\n",
            "Epoch 122/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 1.3977\n",
            "Epoch 123/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 1.3123\n",
            "Epoch 124/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 1.2124\n",
            "Epoch 125/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 1.1188\n",
            "Epoch 126/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 1.0484\n",
            "Epoch 127/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.9725\n",
            "Epoch 128/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.9027\n",
            "Epoch 129/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.8358\n",
            "Epoch 130/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.7790\n",
            "Epoch 131/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.7321\n",
            "Epoch 132/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.6906\n",
            "Epoch 133/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.6414\n",
            "Epoch 134/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.5983\n",
            "Epoch 135/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.5601\n",
            "Epoch 136/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.5221\n",
            "Epoch 137/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.4872\n",
            "Epoch 138/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.4697\n",
            "Epoch 139/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.4376\n",
            "Epoch 140/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.4266\n",
            "Epoch 141/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.3991\n",
            "Epoch 142/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.3729\n",
            "Epoch 143/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.3664\n",
            "Epoch 144/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.3470\n",
            "Epoch 145/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.3306\n",
            "Epoch 146/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.3296\n",
            "Epoch 147/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.3042\n",
            "Epoch 148/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.2967\n",
            "Epoch 149/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.2965\n",
            "Epoch 150/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.2857\n",
            "Epoch 151/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.2678\n",
            "Epoch 152/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.2574\n",
            "Epoch 153/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.2602\n",
            "Epoch 154/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.2486\n",
            "Epoch 155/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.2399\n",
            "Epoch 156/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.2407\n",
            "Epoch 157/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.2291\n",
            "Epoch 158/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.2226\n",
            "Epoch 159/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.2279\n",
            "Epoch 160/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.2104\n",
            "Epoch 161/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.2040\n",
            "Epoch 162/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.2099\n",
            "Epoch 163/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1966\n",
            "Epoch 164/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.2000\n",
            "Epoch 165/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.1948\n",
            "Epoch 166/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1916\n",
            "Epoch 167/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1940\n",
            "Epoch 168/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1822\n",
            "Epoch 169/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1796\n",
            "Epoch 170/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1793\n",
            "Epoch 171/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1728\n",
            "Epoch 172/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1702\n",
            "Epoch 173/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1667\n",
            "Epoch 174/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1677\n",
            "Epoch 175/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1687\n",
            "Epoch 176/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1579\n",
            "Epoch 177/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.1582\n",
            "Epoch 178/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.1581\n",
            "Epoch 179/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.1506\n",
            "Epoch 180/200\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.1542\n",
            "Epoch 181/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1508\n",
            "Epoch 182/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1502\n",
            "Epoch 183/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1451\n",
            "Epoch 184/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1442\n",
            "Epoch 185/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1454\n",
            "Epoch 186/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1405\n",
            "Epoch 187/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1428\n",
            "Epoch 188/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1485\n",
            "Epoch 189/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1466\n",
            "Epoch 190/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1418\n",
            "Epoch 191/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1393\n",
            "Epoch 192/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1404\n",
            "Epoch 193/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1409\n",
            "Epoch 194/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1366\n",
            "Epoch 195/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1381\n",
            "Epoch 196/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1291\n",
            "Epoch 197/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1285\n",
            "Epoch 198/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1348\n",
            "Epoch 199/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1301\n",
            "Epoch 200/200\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.1391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ_4OuPMsgpl"
      },
      "source": [
        "generic test музыки ниже"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoP6a1BPfYee"
      },
      "source": [
        "def generate():\r\n",
        "    \"\"\" Generate a piano midi file \"\"\"\r\n",
        "    #load the notes used to train the model\r\n",
        "    with open('notes', 'rb') as filepath:\r\n",
        "        notes = pickle.load(filepath)\r\n",
        "\r\n",
        "    # Get all pitch names\r\n",
        "    pitchnames = sorted(set(item for item in notes))\r\n",
        "    # Get all pitch names\r\n",
        "    n_vocab = len(set(notes))\r\n",
        "\r\n",
        "    network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)\r\n",
        "    model = create_network(normalized_input, n_vocab)\r\n",
        "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\r\n",
        "    create_midi(prediction_output)\r\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq3BDWkmk9OZ"
      },
      "source": [
        "Подготовление последовательностей, используемых нейронной сетью"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x40JY_D0s2mb"
      },
      "source": [
        "def prepare_sequences(notes, pitchnames, n_vocab):\r\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\r\n",
        "    # map between notes and integers and back\r\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\r\n",
        "\r\n",
        "    sequence_length = 100\r\n",
        "    network_input = []\r\n",
        "    output = []\r\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\r\n",
        "        sequence_in = notes[i:i + sequence_length]\r\n",
        "        sequence_out = notes[i + sequence_length]\r\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\r\n",
        "        output.append(note_to_int[sequence_out])\r\n",
        "\r\n",
        "    n_patterns = len(network_input)\r\n",
        "\r\n",
        "    # reshape the input into a format compatible with LSTM layers\r\n",
        "    normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\r\n",
        "    # normalize input\r\n",
        "    normalized_input = normalized_input / float(n_vocab)\r\n",
        "\r\n",
        "    return (network_input, normalized_input)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cmIUx3RlJsY"
      },
      "source": [
        "Создание структуры нейронной сети"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxarXDLws6yr"
      },
      "source": [
        "def create_network(network_input, n_vocab):\r\n",
        "    \"\"\" create the structure of the neural network \"\"\"\r\n",
        "    model = Sequential()\r\n",
        "    model.add(LSTM(\r\n",
        "        512,\r\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\r\n",
        "        return_sequences=True\r\n",
        "        ))\r\n",
        "    model.add(Dropout(0.3))\r\n",
        "    model.add(LSTM(512, return_sequences=True))\r\n",
        "    model.add(Dropout(0.3))\r\n",
        "    model.add(LSTM(512))\r\n",
        "    model.add(Dense(256))\r\n",
        "    model.add(Dropout(0.3))\r\n",
        "    model.add(Dense(n_vocab))\r\n",
        "    model.add(Activation('softmax'))\r\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\r\n",
        "\r\n",
        "\r\n",
        "    # Load the weights to each node\r\n",
        "    model.load_weights('weights-improvement-99-4.6475-bigger.hdf5')\r\n",
        "\r\n",
        "    return model\r\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AatEAsqjlS28"
      },
      "source": [
        "Генерация нот из нейронной сети на основе последовательности нот"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33lqgJDxs_Ez"
      },
      "source": [
        "def generate_notes(model, network_input, pitchnames, n_vocab):\r\n",
        "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\r\n",
        "    # pick a random sequence from the input as a starting point for the prediction\r\n",
        "    start = numpy.random.randint(0, len(network_input)-1)\r\n",
        "\r\n",
        "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\r\n",
        "\r\n",
        "    pattern = network_input[start]\r\n",
        "    prediction_output = []\r\n",
        "\r\n",
        "    # generate 500 notes\r\n",
        "    for note_index in range(500):\r\n",
        "        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\r\n",
        "        prediction_input = prediction_input / float(n_vocab)\r\n",
        "\r\n",
        "        prediction = model.predict(prediction_input, verbose=0)\r\n",
        "\r\n",
        "        index = numpy.argmax(prediction)\r\n",
        "        result = int_to_note[index]\r\n",
        "        prediction_output.append(result)\r\n",
        "\r\n",
        "        pattern.append(index)\r\n",
        "        pattern = pattern[1:len(pattern)]\r\n",
        "\r\n",
        "    return prediction_output\r\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA8CwsirtDRj"
      },
      "source": [
        "def create_midi(prediction_output):\r\n",
        "    \"\"\" convert the output from the prediction to notes and create a midi file\r\n",
        "        from the notes \"\"\"\r\n",
        "    offset = 0\r\n",
        "    output_notes = []\r\n",
        "\r\n",
        "    # create note and chord objects based on the values generated by the model\r\n",
        "    for pattern in prediction_output:\r\n",
        "        # pattern is a chord\r\n",
        "        if ('.' in pattern) or pattern.isdigit():\r\n",
        "            notes_in_chord = pattern.split('.')\r\n",
        "            notes = []\r\n",
        "            for current_note in notes_in_chord:\r\n",
        "                new_note = note.Note(int(current_note))\r\n",
        "                new_note.storedInstrument = instrument.Piano()\r\n",
        "                notes.append(new_note)\r\n",
        "            new_chord = chord.Chord(notes)\r\n",
        "            new_chord.offset = offset\r\n",
        "            output_notes.append(new_chord)\r\n",
        "        # pattern is a note\r\n",
        "        else:\r\n",
        "            new_note = note.Note(pattern)\r\n",
        "            new_note.offset = offset\r\n",
        "            new_note.storedInstrument = instrument.Piano()\r\n",
        "            output_notes.append(new_note)\r\n",
        "\r\n",
        "        # increase offset each iteration so that notes do not stack\r\n",
        "        offset += 0.5\r\n",
        "\r\n",
        "    midi_stream = stream.Stream(output_notes)\r\n",
        "\r\n",
        "    midi_stream.write('midi', fp='test_output.mid')\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    generate()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NybpkZECZIa7"
      },
      "source": [
        "# Example two\r\n",
        "new bad version\r\n",
        "faled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-6aCfWlZLAM"
      },
      "source": [
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "# ignore all info and warning messages\r\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \r\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\r\n",
        "\r\n",
        "import glob\r\n",
        "import pickle\r\n",
        "import numpy\r\n",
        "import sys\r\n",
        "import keras\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "from music21 import converter, instrument, note, chord\r\n",
        "from datetime import datetime\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Dropout\r\n",
        "from keras.layers import LSTM\r\n",
        "from keras.layers import Activation\r\n",
        "from keras.utils import np_utils\r\n",
        "from keras.callbacks import TensorBoard\r\n",
        "from shutil import copyfile"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pm5TJeKbZnSD",
        "outputId": "a8222fd9-c81c-495b-c77a-745ae5d7139f"
      },
      "source": [
        "# name of midi file directory, model directory, model file prefix, and epochs\r\n",
        "mididirectory = str(sys.argv[1])\r\n",
        "modeldirectory = str(sys.argv[2])\r\n",
        "modelfileprefix = str(sys.argv[3])\r\n",
        "modelepochs = int(sys.argv[4])\r\n",
        "\r\n",
        "notesfile = modeldirectory + modelfileprefix + '.notes'"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-0644aa112bff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmididirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodeldirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodelfileprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodelepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Z5oRa7ZGZsIR",
        "outputId": "0d06d2de-3be6-4631-bdbb-2008f034941e"
      },
      "source": [
        "# callback to save model and plot stats every 25 epochs\r\n",
        "class CustomSaver(keras.callbacks.Callback):\r\n",
        "\tdef __init__(self):\r\n",
        "\t\tself.epoch = 0\t\r\n",
        "\t# This function is called when the training begins\r\n",
        "\tdef on_train_begin(self, logs={}):\r\n",
        "\t\t# Initialize the lists for holding the logs, losses and accuracies\r\n",
        "\t\tself.losses = []\r\n",
        "\t\tself.acc = []\r\n",
        "\t\tself.logs = []\r\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\r\n",
        "\t\t# Append the logs, losses and accuracies to the lists\r\n",
        "\t\tself.logs.append(logs)\r\n",
        "\t\tself.losses.append(logs.get('loss'))\r\n",
        "\t\tself.acc.append(logs.get('acc')*100)\r\n",
        "\t\t# save model and plt every 50 epochs\r\n",
        "\t\tif (epoch+1) % 25 == 0:\r\n",
        "\t\t\tsys.stdout.write(\"\\nAuto-saving model and plot after {} epochs to \".format(epoch+1)+\"\\n\"+modeldirectory + modelfileprefix + \"_\" + str(epoch+1).zfill(3) + \".model\\n\"+modeldirectory + modelfileprefix + \"_\" + str(epoch+1).zfill(3) + \".png\\n\\n\")\r\n",
        "\t\t\tsys.stdout.flush()\r\n",
        "\t\t\tself.model.save(modeldirectory + modelfileprefix + '_' + str(epoch+1).zfill(3) + '.model')\r\n",
        "\t\t\tcopyfile(notesfile,modeldirectory + modelfileprefix + '_' + str(epoch+1).zfill(3) + '.notes');\r\n",
        "\t\t\tN = numpy.arange(0, len(self.losses))\r\n",
        "\t\t\t# Plot train loss, train acc, val loss and val acc against epochs passed\r\n",
        "\t\t\tplt.figure()\r\n",
        "\t\t\tplt.subplots_adjust(hspace=0.7)\r\n",
        "\t\t\tplt.subplot(2, 1, 1)\r\n",
        "\t\t\t# plot loss values\r\n",
        "\t\t\tplt.plot(N, self.losses, label = \"train_loss\")\r\n",
        "\t\t\tplt.title(\"Loss [Epoch {}]\".format(epoch+1))\r\n",
        "\t\t\tplt.xlabel('Epoch')\r\n",
        "\t\t\tplt.ylabel('Loss')\r\n",
        "\t\t\tplt.subplot(2, 1, 2)\r\n",
        "\t\t\t# plot accuracy values\r\n",
        "\t\t\tplt.plot(N, self.acc, label = \"train_acc\")\r\n",
        "\t\t\tplt.title(\"Accuracy % [Epoch {}]\".format(epoch+1))\r\n",
        "\t\t\tplt.xlabel(\"Epoch\")\r\n",
        "\t\t\tplt.ylabel(\"Accuracy %\")\r\n",
        "\t\t\tplt.savefig(modeldirectory + modelfileprefix + '_' + str(epoch+1).zfill(3) + '.png')\r\n",
        "\t\t\tplt.close()\r\n",
        "\t\t\t\r\n",
        "# train the neural network\r\n",
        "def train_network():\r\n",
        "\r\n",
        "\tsys.stdout.write(\"Reading midi files...\\n\\n\")\r\n",
        "\tsys.stdout.flush()\r\n",
        "\r\n",
        "\tnotes = get_notes()\r\n",
        "\r\n",
        "\t# get amount of pitch names\r\n",
        "\tn_vocab = len(set(notes))\r\n",
        "\r\n",
        "\tsys.stdout.write(\"\\nPreparing note sequences...\\n\")\r\n",
        "\tsys.stdout.flush()\r\n",
        "\r\n",
        "\tnetwork_input, network_output = prepare_sequences(notes, n_vocab)\r\n",
        "\r\n",
        "\tsys.stdout.write(\"\\nCreating CuDNNLSTM neural network model...\\n\")\r\n",
        "\tsys.stdout.flush()\r\n",
        "\r\n",
        "\tmodel = create_network(network_input, n_vocab)\r\n",
        "\r\n",
        "\tsys.stdout.write(\"\\nTraining CuDNNLSTM neural network model...\\n\\n\")\r\n",
        "\tsys.stdout.flush()\r\n",
        "\r\n",
        "\ttrain(model, network_input, network_output)\r\n",
        "\r\n",
        "# get all the notes and chords from the midi files\r\n",
        "def get_notes():\r\n",
        "\r\n",
        "\t# remove existing data file if it exists\r\n",
        "\tif os.path.isfile(notesfile):\r\n",
        "\t\tos.remove(notesfile)\r\n",
        "\t\r\n",
        "\tnotes = []\r\n",
        "\r\n",
        "\tfor file in glob.glob(\"{}/*.mid\".format(mididirectory)):\r\n",
        "\t\tmidi = converter.parse(file)\r\n",
        "\r\n",
        "\t\tsys.stdout.write(\"Parsing %s ...\\n\" % file)\r\n",
        "\t\tsys.stdout.flush()\r\n",
        "\r\n",
        "\t\tnotes_to_parse = None\r\n",
        "\r\n",
        "\t\ttry: # file has instrument parts\r\n",
        "\t\t\ts2 = instrument.partitionByInstrument(midi)\r\n",
        "\t\t\tnotes_to_parse = s2.parts[0].recurse() \r\n",
        "\t\texcept: # file has notes in a flat structure\r\n",
        "\t\t\tnotes_to_parse = midi.flat.notes\r\n",
        "\r\n",
        "\t\tfor element in notes_to_parse:\r\n",
        "\t\t\tif isinstance(element, note.Note):\r\n",
        "\t\t\t\tnotes.append(str(element.pitch))\r\n",
        "\t\t\telif isinstance(element, chord.Chord):\r\n",
        "\t\t\t\tnotes.append('.'.join(str(n) for n in element.normalOrder))\r\n",
        "\r\n",
        "\twith open(notesfile,'wb') as filepath:\r\n",
        "\t\tpickle.dump(notes, filepath)\r\n",
        "\r\n",
        "\treturn notes\r\n",
        "\r\n",
        "# prepare the sequences used by the neural network\r\n",
        "def prepare_sequences(notes, n_vocab):\r\n",
        "\tsequence_length = 100\r\n",
        "\r\n",
        "\t# get all pitch names\r\n",
        "\tpitchnames = sorted(set(item for item in notes))\r\n",
        "\r\n",
        "\t # create a dictionary to map pitches to integers\r\n",
        "\tnote_to_int = dict((note, number) for number, note in enumerate(pitchnames))\r\n",
        "\r\n",
        "\tnetwork_input = []\r\n",
        "\tnetwork_output = []\r\n",
        "\r\n",
        "\t# create input sequences and the corresponding outputs\r\n",
        "\tfor i in range(0, len(notes) - sequence_length, 1):\r\n",
        "\t\tsequence_in = notes[i:i + sequence_length] # needs to take into account if notes in midi file are less than required 100 ( mod ? )\r\n",
        "\t\tsequence_out = notes[i + sequence_length]  # needs to take into account if notes in midi file are less than required 100 ( mod ? )\r\n",
        "\t\tnetwork_input.append([note_to_int[char] for char in sequence_in])\r\n",
        "\t\tnetwork_output.append(note_to_int[sequence_out])\r\n",
        "\r\n",
        "\tn_patterns = len(network_input)\r\n",
        "\r\n",
        "\t# reshape the input into a format compatible with CuDNNLSTM layers\r\n",
        "\tnetwork_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\r\n",
        "\t# normalize input\r\n",
        "\tnetwork_input = network_input / float(n_vocab)\r\n",
        "\r\n",
        "\tnetwork_output = np_utils.to_categorical(network_output)\r\n",
        "\r\n",
        "\treturn (network_input, network_output)\r\n",
        "\r\n",
        "# create the structure of the neural network\r\n",
        "def create_network(network_input, n_vocab):\r\n",
        "\r\n",
        "\t'''\r\n",
        "\t\"\"\" create the structure of the neural network \"\"\"\r\n",
        "\tmodel = Sequential()\r\n",
        "\tmodel.add(CuDNNLSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))\r\n",
        "\tmodel.add(Dropout(0.3))\r\n",
        "\tmodel.add(CuDNNLSTM(512, return_sequences=True))\r\n",
        "\tmodel.add(Dropout(0.3))\r\n",
        "\tmodel.add(CuDNNLSTM(512))\r\n",
        "\tmodel.add(Dense(256))\r\n",
        "\tmodel.add(Dropout(0.3))\r\n",
        "\tmodel.add(Dense(n_vocab))\r\n",
        "\tmodel.add(Activation('softmax'))\r\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=[\"accuracy\"])\r\n",
        "\t'''\r\n",
        "\t\r\n",
        "\tmodel = Sequential()\r\n",
        "\t\r\n",
        "\tmodel.add(CuDNNLSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))\r\n",
        "\tmodel.add(Dropout(0.2))\r\n",
        "\tmodel.add(BatchNormalization())\r\n",
        "\t\r\n",
        "\tmodel.add(CuDNNLSTM(256))\r\n",
        "\tmodel.add(Dropout(0.2))\r\n",
        "\tmodel.add(BatchNormalization())\r\n",
        "\t\r\n",
        "\tmodel.add(Dense(128, activation=\"relu\"))\r\n",
        "\tmodel.add(Dropout(0.2))\r\n",
        "\tmodel.add(BatchNormalization())\r\n",
        "\t\r\n",
        "\tmodel.add(Dense(n_vocab))\r\n",
        "\tmodel.add(Activation('softmax'))\r\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\r\n",
        "\t\r\n",
        "\treturn model\r\n",
        "\r\n",
        "# train the neural network\r\n",
        "def train(model, network_input, network_output):\r\n",
        "\t\r\n",
        "\t# saver = CustomSaver()\r\n",
        "\t# history = model.fit(network_input, network_output, epochs=modelepochs, batch_size=50, callbacks=[tensorboard])\r\n",
        "\thistory = model.fit(network_input, network_output, epochs=modelepochs, batch_size=50, callbacks=[CustomSaver()])\r\n",
        "\r\n",
        "\t# evaluate the model\r\n",
        "\tprint(\"\\nModel evaluation at the end of training\")\r\n",
        "\ttrain_acc = model.evaluate(network_input, network_output, verbose=0)\r\n",
        "\tprint(model.metrics_names)\r\n",
        "\tprint(train_acc)\r\n",
        "\t\r\n",
        "\t# save trained model\r\n",
        "\tmodel.save(modeldirectory + modelfileprefix + '_' + str(modelepochs) + '.model')\r\n",
        "\r\n",
        "\t# delete temp notes file\r\n",
        "\tos.remove(notesfile)\r\n",
        "\t\r\n",
        "if __name__ == '__main__':\r\n",
        "\ttrain_network()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading midi files...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-56dea333ad91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-56dea333ad91>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mnotes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_notes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# get amount of pitch names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-56dea333ad91>\u001b[0m in \u001b[0;36mget_notes\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# remove existing data file if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotesfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotesfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'notesfile' is not defined"
          ]
        }
      ]
    }
  ]
}